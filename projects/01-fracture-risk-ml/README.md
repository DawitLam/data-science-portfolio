# Fracture Risk ML Pipeline

**Advanced machine learning pipeline for predicting fracture risk in elderly patients**

[![Python](https://img.shields.io/badge/Python-3.9+-blue)](https://python.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-orange)](https://scikit-learn.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://docker.com)

## ğŸ¯ Project Overview

This project demonstrates a complete end-to-end machine learning pipeline for predicting fracture risk in elderly patients. It showcases advanced ML engineering practices, healthcare domain expertise, and production-ready deployment capabilities.

### ğŸš€ Key Features

- **Advanced Feature Engineering**: Medical domain-specific features and transformations
- **Multiple ML Algorithms**: Random Forest, XGBoost, LightGBM, and Neural Networks
- **Hyperparameter Optimization**: Automated tuning with Optuna
- **Model Interpretability**: SHAP values and feature importance analysis
- **RESTful API**: FastAPI-based model serving
- **MLOps Integration**: Model versioning with MLflow
- **Comprehensive Testing**: Unit tests and integration tests
- **Docker Deployment**: Containerized application

## ğŸ“Š Model Performance

Current best model performance on validation set:
- **Algorithm**: XGBoost Classifier
- **AUC-ROC**: 0.847
- **Precision**: 0.782
- **Recall**: 0.734
- **F1-Score**: 0.757

## ğŸ—‚ï¸ Project Structure

```
01-fracture-risk-ml/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model_config.yaml       # Model hyperparameters
â”‚   â”œâ”€â”€ feature_config.yaml     # Feature engineering settings
â”‚   â””â”€â”€ api_config.yaml         # API configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw data (gitignored)
â”‚   â”œâ”€â”€ processed/              # Processed datasets
â”‚   â””â”€â”€ features/               # Feature-engineered data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_models/         # Serialized models
â”‚   â”œâ”€â”€ experiments/            # MLflow experiment tracking
â”‚   â””â”€â”€ artifacts/              # Model artifacts and metrics
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_development.ipynb
â”‚   â”œâ”€â”€ 04_model_evaluation.ipynb
â”‚   â””â”€â”€ 05_model_interpretation.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_data.py        # Data loading utilities
â”‚   â”‚   â”œâ”€â”€ preprocess.py       # Data preprocessing
â”‚   â”‚   â””â”€â”€ validate.py         # Data validation
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ build_features.py   # Feature engineering
â”‚   â”‚   â”œâ”€â”€ medical_features.py # Domain-specific features
â”‚   â”‚   â””â”€â”€ selection.py        # Feature selection
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train_model.py      # Model training pipeline
â”‚   â”‚   â”œâ”€â”€ predict_model.py    # Prediction pipeline
â”‚   â”‚   â”œâ”€â”€ evaluate.py         # Model evaluation
â”‚   â”‚   â””â”€â”€ optimize.py         # Hyperparameter optimization
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”‚   â”œâ”€â”€ models.py           # Pydantic models
â”‚   â”‚   â””â”€â”€ endpoints.py        # API endpoints
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Configuration management
â”‚       â”œâ”€â”€ logging.py          # Logging utilities
â”‚       â””â”€â”€ metrics.py          # Custom metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data/              # Test data processing
â”‚   â”œâ”€â”€ test_features/          # Test feature engineering
â”‚   â”œâ”€â”€ test_models/            # Test model training
â”‚   â””â”€â”€ test_api/               # Test API endpoints
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ Dockerfile              # Docker configuration
â”‚   â”œâ”€â”€ docker-compose.yml      # Multi-container setup
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ startup.sh              # Application startup script
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ api_documentation.md    # API documentation
â”‚   â”œâ”€â”€ model_documentation.md  # Model methodology
â”‚   â””â”€â”€ deployment_guide.md     # Deployment instructions
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Docker (optional, for containerized deployment)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/DawitLam/data-science-portfolio.git
cd data-science-portfolio/projects/01-fracture-risk-ml
```

2. **Set up virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Generate synthetic data** (from project root)
```bash
cd ../..
python shared/data_generators/synthetic_medical_data_generator.py
cd projects/01-fracture-risk-ml
```

4. **Run the training pipeline**
```bash
python src/models/train_model.py
```

### Try it locally (Windows PowerShell)
Copy these commands into PowerShell. They assume you've already created the repo-level virtual environment as shown in the main README.

```powershell
# From repo root
Set-Location .\projects\01-fracture-risk-ml

# Activate repo venv (if created at repo root)
.\.venv\Scripts\Activate.ps1

# Train a model (quick demo)
python .\src\models\train_model.py

# Start the API (open http://127.0.0.1:8000/docs)
uvicorn src.api.main:app --reload --host 127.0.0.1 --port 8000
```

5. **Start the API server**
```bash
uvicorn src.api.main:app --reload
```

## ğŸ”¬ Usage Examples

### Training a Model
```python
from src.models.train_model import train_fracture_risk_model
from src.data.load_data import load_training_data

# Load data
X_train, X_val, y_train, y_val = load_training_data()

# Train model
model, metrics = train_fracture_risk_model(
    X_train, y_train, 
    X_val, y_val,
    algorithm='xgboost'
)

print(f"Model AUC: {metrics['auc']:.3f}")
```

### Making Predictions
```python
from src.models.predict_model import FractureRiskPredictor

# Initialize predictor
predictor = FractureRiskPredictor('models/trained_models/best_model.pkl')

# Make prediction
patient_data = {
    'age': 72,
    'gender': 'Female',
    'bmi': 22.1,
    'spine_t_score': -2.8,
    'hip_t_score': -2.1,
    'vitamin_d_ng_ml': 18.5,
    'grip_strength_kg': 18.2,
    'previous_fracture_count': 1
}

risk_score = predictor.predict_risk(patient_data)
print(f"Fracture Risk Score: {risk_score:.3f}")
```

### API Usage
```bash
# Health check
curl http://localhost:8000/health

# Predict fracture risk
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "age": 72,
    "gender": "Female",
    "bmi": 22.1,
    "spine_t_score": -2.8,
    "hip_t_score": -2.1,
    "vitamin_d_ng_ml": 18.5,
    "grip_strength_kg": 18.2,
    "previous_fracture_count": 1
  }'
```

## ğŸ“ˆ Model Development Process

### 1. Data Exploration & Analysis
- **Statistical Analysis**: Distribution analysis, correlation studies
- **Medical Validation**: Clinical plausibility checks
- **Missing Data Analysis**: Patterns and imputation strategies

### 2. Feature Engineering
- **Medical Domain Features**: FRAX score components, risk ratios
- **Derived Variables**: BMI categories, T-score classifications
- **Interaction Features**: Age-gender, BMI-bone density interactions
- **Temporal Features**: Time since measurements, seasonal effects

### 3. Model Selection & Training
- **Baseline Models**: Logistic Regression, Random Forest
- **Advanced Models**: XGBoost, LightGBM, CatBoost
- **Ensemble Methods**: Voting classifiers, stacking
- **Deep Learning**: Neural networks for complex patterns

### 4. Model Optimization
- **Hyperparameter Tuning**: Optuna-based optimization
- **Cross-Validation**: Stratified K-fold validation
- **Feature Selection**: Recursive feature elimination, SHAP-based selection
- **Class Imbalance**: SMOTE, class weights, threshold optimization

### 5. Evaluation & Interpretation
- **Performance Metrics**: AUC-ROC, Precision-Recall, Calibration
- **Clinical Metrics**: Sensitivity, Specificity, PPV, NPV
- **Model Interpretation**: SHAP values, LIME, feature importance
- **Bias Analysis**: Fairness across demographic groups

## ğŸ¥ Clinical Context

### Fracture Risk Factors
The model incorporates evidence-based risk factors from medical literature:

**Primary Risk Factors**:
- Age (exponential increase after 65)
- Gender (postmenopausal women highest risk)
- Bone mineral density (T-scores)
- Previous fracture history
- Family history of fractures

**Secondary Risk Factors**:
- Low BMI (<20 kg/mÂ²)
- Smoking status
- Alcohol consumption
- Physical activity level
- Vitamin D deficiency
- Certain medications

### Model Validation
- **Clinical Validation**: Compared against FRAX calculator
- **External Validation**: Performance on holdout populations
- **Temporal Validation**: Performance over time periods
- **Subgroup Analysis**: Performance across age/gender groups

## ğŸ”§ Configuration

### Model Configuration (`config/model_config.yaml`)
```yaml
models:
  xgboost:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    random_state: 42
  
  random_forest:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 5
    min_samples_leaf: 2
    random_state: 42

training:
  test_size: 0.2
  validation_size: 0.2
  cross_validation_folds: 5
  random_state: 42

optimization:
  n_trials: 100
  timeout: 3600  # 1 hour
  direction: maximize
  metric: roc_auc
```

## ğŸ³ Docker Deployment

### Build and Run
```bash
# Build Docker image
docker build -t fracture-risk-api .

# Run container
docker run -p 8000:8000 fracture-risk-api

# Or use docker-compose
docker-compose up
```

## ğŸ§ª Testing

### Run Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test module
pytest tests/test_models/
```

### Test Categories
- **Unit Tests**: Individual function testing
- **Integration Tests**: End-to-end pipeline testing
- **API Tests**: Endpoint functionality testing
- **Data Tests**: Data validation and schema testing

## ğŸ“Š Monitoring & MLOps

### MLflow Integration
- **Experiment Tracking**: Model parameters, metrics, artifacts
- **Model Registry**: Version control and stage management
- **Model Serving**: Direct model deployment capabilities

### Monitoring Dashboard
- **Model Performance**: Real-time accuracy tracking
- **Data Drift**: Input distribution monitoring
- **Prediction Distribution**: Output pattern analysis
- **System Health**: API response times, error rates

## ğŸ”® Future Enhancements

### Technical Improvements
- **Real-time Predictions**: Streaming data processing
- **Federated Learning**: Multi-site model training
- **Automated Retraining**: Continuous model updates
- **A/B Testing**: Model variant comparison

### Clinical Extensions
- **Multi-outcome Prediction**: Hip vs. vertebral fractures
- **Treatment Recommendations**: Personalized interventions
- **Risk Trajectories**: Longitudinal risk modeling
- **Integration**: EHR system connectivity

## ğŸ“š References

1. Kanis JA, et al. FRAX and the assessment of fracture probability in men and women from the UK. Osteoporos Int. 2008.
2. Cosman F, et al. Clinician's Guide to Prevention and Treatment of Osteoporosis. Osteoporos Int. 2014.
3. Compston J, et al. UK clinical guideline for the prevention and treatment of osteoporosis. Arch Osteoporos. 2017.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Dawit Lambebo Gulta**
- Email: dawit.lambebo@gmail.com
- LinkedIn: [linkedin.com/in/dawit-lambebo-gulta](https://www.linkedin.com/in/dawit-lambebo-gulta/)
- GitHub: [github.com/DawitLam](https://github.com/DawitLam)

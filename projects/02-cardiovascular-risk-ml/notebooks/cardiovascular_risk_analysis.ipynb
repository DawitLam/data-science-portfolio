{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fa9cac",
   "metadata": {},
   "source": [
    "# Cardiovascular Risk Assessment — Reproducible Notebook\n",
    "\n",
    "This notebook demonstrates an end-to-end ML workflow using entirely synthetic data. It replicates the methodology from your fracture-risk project (data generation → preprocessing → feature engineering → model training → evaluation → clinical interpretation) while avoiding any original dataset or SINS content.\n",
    "\n",
    "Guidelines:\n",
    "- This notebook uses the shared synthetic data generator in `shared/data_generators/cardiovascular_data_generator.py`.\n",
    "- Do not load or reference any private datasets.\n",
    "- Run cells sequentially to reproduce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Optional high-performance libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "# Imbalanced learning\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "except Exception:\n",
    "    SMOTE = None\n",
    "    ImbPipeline = None\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, auc, accuracy_score, recall_score\n",
    ")\n",
    "\n",
    "# SHAP (optional)\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    shap = None\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 200)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a84c5",
   "metadata": {},
   "source": [
    "## Section 2: Generate Synthetic Dataset\n",
    "\n",
    "We will generate a synthetic cardiovascular dataset with realistic clinical relationships, using the shared generator. This avoids any use of private or original fracture-risk data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241fec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data using the shared generator\n",
    "from shared.data_generators.cardiovascular_data_generator import generate_cardiovascular_data\n",
    "\n",
    "# generate a moderate-size dataset for notebook demo\n",
    "df = generate_cardiovascular_data(n_samples=5000)\n",
    "\n",
    "# quick peek\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6ac1e",
   "metadata": {},
   "source": [
    "## Section 3: Data Preprocessing and Feature Engineering\n",
    "\n",
    "Handle missing values, create derived features, and prepare data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd440b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic checks\n",
    "print(df.isna().mean().round(3).sort_values(ascending=False).head(10))\n",
    "\n",
    "# Derived features examples\n",
    "# pulse_pressure, total_hdl_ratio, bmi_category\n",
    "\n",
    "df['pulse_pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "df['total_hdl_ratio'] = df['total_cholesterol'] / (df['hdl_cholesterol'].replace(0, np.nan))\n",
    "\n",
    "def bmi_category(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'underweight'\n",
    "    if bmi < 25:\n",
    "        return 'normal'\n",
    "    if bmi < 30:\n",
    "        return 'overweight'\n",
    "    if bmi < 35:\n",
    "        return 'obese1'\n",
    "    return 'obese2'\n",
    "\n",
    "df['bmi_category'] = df['bmi'].apply(bmi_category)\n",
    "\n",
    "# Convert some binary columns to int (ensure clean types)\n",
    "binary_cols = ['smoking_status','diabetes','hypertension','family_history_cvd','previous_mi','previous_stroke','on_statin_therapy','on_bp_medication']\n",
    "for c in binary_cols:\n",
    "    df[c] = df[c].astype(int)\n",
    "\n",
    "# Show updated frame\n",
    "print(df[['pulse_pressure','total_hdl_ratio','bmi','bmi_category']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabba92",
   "metadata": {},
   "source": [
    "## Section 4: Exploratory Data Analysis and Visualization\n",
    "\n",
    "Distribution plots, correlation heatmap, and outcome-stratified boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23587fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome distribution\n",
    "sns.countplot(x='cvd_risk_10yr', data=df)\n",
    "plt.title('CVD 10yr High-risk (1) vs Low (0)')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numeric features\n",
    "numeric_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "mask = np.zeros_like(df[numeric_cols].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(df[numeric_cols].corr(), mask=mask, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation heatmap (numeric features)')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of systolic BP by outcome\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='cvd_risk_10yr', y='systolic_bp', data=df)\n",
    "plt.title('Systolic BP by CVD outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ec727",
   "metadata": {},
   "source": [
    "## Section 5: Class Imbalance Analysis\n",
    "\n",
    "Check class imbalance and demonstrate SMOTE effect (if imblearn available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "counts = df['cvd_risk_10yr'].value_counts()\n",
    "print(counts)\n",
    "print('Imbalance ratio (major/minor):', counts.max() / counts.min())\n",
    "\n",
    "# If SMOTE is available, show before/after counts on a small sample\n",
    "if SMOTE is not None:\n",
    "    X = df.drop(columns=['cvd_risk_10yr','patient_id','assessment_date'])\n",
    "    y = df['cvd_risk_10yr']\n",
    "    X_sample, _, y_sample, _ = train_test_split(X, y, stratify=y, test_size=0.9, random_state=42)\n",
    "    print('Sample counts before:', np.bincount(y_sample))\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X_sample.select_dtypes(include=[np.number]).fillna(0), y_sample)\n",
    "    print('Sample counts after SMOTE:', np.bincount(y_res))\n",
    "else:\n",
    "    print('imblearn not installed — skip SMOTE demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adab545",
   "metadata": {},
   "source": [
    "## Section 6: Model Pipeline Development\n",
    "\n",
    "Create preprocessing pipelines (numerical impute/scale, categorical encode) and combine with models. Use stratified splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d225d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature lists\n",
    "exclude = ['patient_id','assessment_date','cvd_risk_10yr']\n",
    "all_features = [c for c in df.columns if c not in exclude]\n",
    "num_features = df[all_features].select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_features = df[all_features].select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "print('numerical:', len(num_features), 'categorical:', len(cat_features))\n",
    "\n",
    "# Preprocessing\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_features),\n",
    "    ('cat', cat_pipe, cat_features)\n",
    "])\n",
    "\n",
    "# Example model pipelines\n",
    "models = {\n",
    "    'logistic': LogisticRegression(max_iter=1000),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "if xgb is not None:\n",
    "    models['xgboost'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "if lgb is not None:\n",
    "    models['lightgbm'] = lgb.LGBMClassifier()\n",
    "\n",
    "pipelines = {name: Pipeline([('pre', preprocessor), ('clf', clf)]) for name, clf in models.items()}\n",
    "\n",
    "# Train/val/test split\n",
    "X = df[all_features]\n",
    "y = df['cvd_risk_10yr']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print('train/val/test sizes:', X_train.shape[0], X_val.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32b537",
   "metadata": {},
   "source": [
    "## Section 7: Machine Learning Model Training\n",
    "\n",
    "Train multiple models with cross-validation; report validation AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43322d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    print('Training', name)\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    results[name] = scores\n",
    "    print(f'{name} AUC: mean={scores.mean():.3f} std={scores.std():.3f}')\n",
    "\n",
    "# Fit final models on full training set\n",
    "fitted_models = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted_models[name] = pipe\n",
    "\n",
    "print('models trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbf2d2",
   "metadata": {},
   "source": [
    "## Section 8: Model Performance Evaluation\n",
    "\n",
    "Evaluate trained models on the test set with multiple metrics and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "perf = {}\n",
    "for name, model in fitted_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, 'predict_proba') else model.decision_function(X_test)\n",
    "    auc_score = roc_auc_score(y_test, y_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    perf[name] = {'auc': auc_score, 'accuracy': acc, 'recall': rec, 'precision': prec, 'f1': f1, 'cm': cm}\n",
    "    print(f\"{name}: AUC={auc_score:.3f}, accuracy={acc:.3f}, recall={rec:.3f}, precision={prec:.3f}, f1={f1:.3f}\")\n",
    "\n",
    "# Show comparison table\n",
    "pd.DataFrame({k: {m: v for m, v in perf[k].items() if m!='cm'} for k in perf}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4dce08",
   "metadata": {},
   "source": [
    "## Section 9: Feature Importance Analysis\n",
    "\n",
    "Extract feature importances from tree-based models and compare ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from preprocessor\n",
    "num_out = num_features\n",
    "cat_out = list(pipelines['random_forest'].named_steps['pre'].named_transformers_['cat'].named_steps['ohe'].get_feature_names_out(cat_features)) if len(cat_features)>0 else []\n",
    "feature_names = num_out + cat_out\n",
    "\n",
    "# Random Forest importances\n",
    "if 'random_forest' in fitted_models:\n",
    "    rf = fitted_models['random_forest'].named_steps['clf']\n",
    "    importances = rf.feature_importances_\n",
    "    fi = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(20)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    fi.plot.barh()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Random Forest - Top 20 feature importances')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Random forest not trained')\n",
    "\n",
    "# SHAP example (if available)\n",
    "if shap is not None and 'xgboost' in fitted_models:\n",
    "    explainer = shap.TreeExplainer(fitted_models['xgboost'].named_steps['clf'])\n",
    "    X_num = fitted_models['xgboost'].named_steps['pre'].transform(X_test)[:, :len(num_out)]\n",
    "    shap_values = explainer.shap_values(X_num)\n",
    "    shap.summary_plot(shap_values, features=X_test[num_out], feature_names=num_out)\n",
    "else:\n",
    "    print('SHAP or XGBoost not available for summary plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c4dc7",
   "metadata": {},
   "source": [
    "## Section 10: Clinical Threshold Analysis\n",
    "\n",
    "Implement a simple clinical rule (composite score) and compare operating points vs model probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple clinical score: age_points + bp + smoking + diabetes\n",
    "\n",
    "def clinical_score(row):\n",
    "    score = 0\n",
    "    score += max(0, (row['age'] - 45) / 5)\n",
    "    score += 1 if row['systolic_bp'] > 140 else 0\n",
    "    score += 1 if row['smoking_status'] == 1 else 0\n",
    "    score += 2 if row['diabetes'] == 1 else 0\n",
    "    return score\n",
    "\n",
    "X_test2 = X_test.copy()\n",
    "X_test2['clinical_score'] = X_test2.apply(clinical_score, axis=1)\n",
    "\n",
    "# Evaluate rule at threshold >=2\n",
    "rule_pred = (X_test2['clinical_score'] >= 2).astype(int)\n",
    "print('Clinical rule performance:')\n",
    "print('accuracy', accuracy_score(y_test, rule_pred))\n",
    "print('recall', recall_score(y_test, rule_pred))\n",
    "print('precision', precision_score(y_test, rule_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf90c8",
   "metadata": {},
   "source": [
    "## Section 11: Results Comparison and Visualization\n",
    "\n",
    "Compare ROC curves, precision-recall, and a summary table of all models and the clinical rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50829930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for name, model in fitted_models.items():\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={perf[name]['auc']:.2f})\")\n",
    "\n",
    "# clinical rule as a point\n",
    "from sklearn.metrics import roc_curve\n",
    "rule_scores = X_test2['clinical_score']\n",
    "fpr_r, tpr_r, _ = roc_curve(y_test, rule_scores)\n",
    "plt.plot(fpr_r, tpr_r, label='Clinical rule', linestyle='--')\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Summary table including clinical rule\n",
    "summary = pd.DataFrame({name: {'auc': perf[name]['auc'], 'accuracy': perf[name]['accuracy'], 'recall': perf[name]['recall'], 'precision': perf[name]['precision'], 'f1': perf[name]['f1']} for name in perf}).T\n",
    "summary.loc['clinical_rule'] = [roc_auc_score(y_test, X_test2['clinical_score']), accuracy_score(y_test, rule_pred), recall_score(y_test, rule_pred), precision_score(y_test, rule_pred), f1_score(y_test, rule_pred)]\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60aa97",
   "metadata": {},
   "source": [
    "### Next steps and notes\n",
    "- Tidy hyperparameter tuning with Optuna/RandomizedSearchCV.\n",
    "- Add calibration plots and decision curve analysis for clinical usefulness.\n",
    "- Add fairness checks across demographics (gender, ethnicity).\n",
    "- Save best model artifacts to `models/trained_models` and create a small FastAPI wrapper in `src/api` for demo.\n",
    "\n",
    "This notebook is intentionally synthetic and parallel to your fracture-risk notebook. Use it as a reproducible portfolio artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1974ff8",
   "metadata": {},
   "source": [
    "# Visualizations: ROC, Calibration, Feature Importance\n",
    "\n",
    "This section demonstrates model evaluation and explainability visuals using the saved model artifact: ROC curve, calibration (reliability) plot, and feature importances. It also shows a short scoring demo using a few synthetic patient records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports, load saved model artifact, and prepare data for evaluation\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay, calibration_curve, brier_score_loss\n",
    "%matplotlib inline\n",
    "\n",
    "# Resolve repo root and ensure it is on sys.path\n",
    "repo_root = Path.cwd()\n",
    "if not (repo_root / \"shared\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from shared.data_generators.cardiovascular_data_generator import generate_cardiovascular_data\n",
    "import etl\n",
    "import cleaning\n",
    "\n",
    "models_dir = repo_root / \"projects\" / \"02-cardiovascular-risk-ml\" / \"models\"\n",
    "meta_path = models_dir / \"metadata.json\"\n",
    "if not meta_path.exists():\n",
    "    raise FileNotFoundError(\"metadata.json not found. Run the training demo (save_and_demo.py) first.\")\n",
    "\n",
    "meta = json.loads(meta_path.read_text())\n",
    "model_file = models_dir / f\"cardio_best_{meta['best_model']}.joblib\"\n",
    "obj = joblib.load(model_file)\n",
    "model = obj['model']\n",
    "features = obj['features']\n",
    "target = obj.get('target', 'cvd_risk_10yr')\n",
    "\n",
    "# Generate a reproducible synthetic evaluation dataset and run ETL/cleaning\n",
    "print('Generating synthetic evaluation data (n=1000)')\n",
    "df = generate_cardiovascular_data(n_samples=1000)\n",
    "df = etl.basic_etl(df)\n",
    "df = cleaning.impute_missing(df)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "print('Data prepared. X shape:', X.shape, 'y distribution:', y.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d86437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "probs = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X)\n",
    "fpr, tpr, _ = roc_curve(y, probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "plt.plot([0,1], [0,1], '--', color='grey', alpha=0.7)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f'AUC = {roc_auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration plot and Brier score\n",
    "prob_true, prob_pred = calibration_curve(y, probs, n_bins=10)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Calibration')\n",
    "plt.plot([0,1], [0,1], '--', color='grey', alpha=0.7)\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "brier = brier_score_loss(y, probs)\n",
    "print(f'Brier score: {brier:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for tree-based models) and simple scoring demo\n",
    "importances = None\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = getattr(model, 'feature_importances_')\n",
    "elif hasattr(getattr(model, 'estimators_', None), '__len__'):\n",
    "    # RandomForest may expose ensemble; average importances\n",
    "    try:\n",
    "        importances = np.mean([est.feature_importances_ for est in model.estimators_], axis=0)\n",
    "    except Exception:\n",
    "        importances = None\n",
    "\n",
    "if importances is not None:\n",
    "    fi = pd.Series(importances, index=features).sort_values(ascending=False).head(20)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x=fi.values, y=fi.index)\n",
    "    plt.title('Top feature importances')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Feature importances not available for this model type.')\n",
    "\n",
    "# Scoring demo: show predictions for first 5 records\n",
    "print('\\nScoring demo (first 5 records):')\n",
    "X_demo = X.iloc[:5]\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    p_demo = model.predict_proba(X_demo)[:, 1]\n",
    "    for i, p in enumerate(p_demo):\n",
    "        print(f'sample {i}: P(high CVD risk) = {p:.3f}')\n",
    "else:\n",
    "    preds = model.predict(X_demo)\n",
    "    for i, p in enumerate(preds):\n",
    "        print(f'sample {i}: pred = {p}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2b8a6",
   "metadata": {},
   "source": [
    "### Bonus: Logistic coefficients, feature importance table, and interactive ROC\n",
    "\n",
    "This final cell shows how to extract coefficient-based importance for linear models (logistic regression), a unified importance table (works for tree-based or linear models), and an interactive ROC curve using Plotly if available. If Plotly is not installed the code will print a helpful message and fall back to the static ROC shown earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to use helper functions added to `ml_analysis.py` to show feature importance and an interactive ROC\n",
    "try:\n",
    "    from ml_analysis import get_feature_importance, plot_interactive_roc\n",
    "except Exception:\n",
    "    # ensure src path is available\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    src_path = Path.cwd() / \"projects\" / \"02-cardiovascular-risk-ml\" / \"src\"\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.insert(0, str(src_path))\n",
    "    from ml_analysis import get_feature_importance, plot_interactive_roc\n",
    "\n",
    "# unwrap pipeline to a fitted estimator if necessary\n",
    "def _unwrap_model(m):\n",
    "    try:\n",
    "        if hasattr(m, 'named_steps'):\n",
    "            return m.named_steps.get('clf', m)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return m\n",
    "\n",
    "est = _unwrap_model(model)\n",
    "\n",
    "# Feature importance / coefficients\n",
    "fi_df = get_feature_importance(est, features)\n",
    "print('Top features by importance (head):')\n",
    "display(fi_df.head(30))\n",
    "\n",
    "# If logistic (coef_ present) show signed coefficients\n",
    "if hasattr(est, 'coef_'):\n",
    "    import pandas as pd\n",
    "    coef = est.coef_\n",
    "    # flatten for binary\n",
    "    coef_vec = coef.ravel() if coef.ndim > 1 else coef\n",
    "    coef_df = pd.DataFrame({'feature': features, 'coef': coef_vec})\n",
    "    coef_df['abs_coef'] = coef_df['coef'].abs()\n",
    "    coef_df = coef_df.sort_values('abs_coef', ascending=False).reset_index(drop=True)\n",
    "    print('\\nLogistic / linear model coefficients (top):')\n",
    "    display(coef_df.head(20))\n",
    "\n",
    "# Interactive ROC (Plotly) with graceful fallback\n",
    "try:\n",
    "    fig = plot_interactive_roc(est, X, y)\n",
    "    try:\n",
    "        # in notebook this will render interactively\n",
    "        fig.show()\n",
    "    except Exception:\n",
    "        # still write to file for manual inspection\n",
    "        out = str(Path.cwd() / 'projects' / '02-cardiovascular-risk-ml' / 'models' / 'roc_interactive.html')\n",
    "        fig.write_html(out)\n",
    "        print(f'Interactive ROC saved to: {out}')\n",
    "except Exception as e:\n",
    "    print('Interactive ROC unavailable:', e)\n",
    "    print('To enable interactive plots install plotly: pip install plotly')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
